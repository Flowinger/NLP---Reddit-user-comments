{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import requests\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pymongo import MongoClient\n",
    "import os\n",
    "import bz2\n",
    "import re\n",
    "import json\n",
    "import gensim\n",
    "from itertools import chain\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.util import ngrams\n",
    "from nltk.tokenize import word_tokenize, wordpunct_tokenize, WhitespaceTokenizer, sent_tokenize, MWETokenizer\n",
    "from nltk.chunk import ne_chunk\n",
    "from nltk.stem.wordnet import WordNetLemmatizer \n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk import pos_tag\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion, make_pipeline\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn import linear_model\n",
    "from sklearn import ensemble\n",
    "from sklearn import model_selection\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "client = MongoClient(\"mongodb://flow:pass@54.67.100.65/redditdata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db = client.redditdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "comments = db.comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80747895"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': ObjectId('592609bb03723d2a9509c479'),\n",
       " 'author': 'jh99',\n",
       " 'author_flair_css_class': None,\n",
       " 'author_flair_text': None,\n",
       " 'body': 'early 2006 a probable date',\n",
       " 'controversiality': 0,\n",
       " 'created_utc': 1136074029,\n",
       " 'distinguished': None,\n",
       " 'edited': False,\n",
       " 'gilded': 0,\n",
       " 'id': 'c2715',\n",
       " 'link_id': 't3_22569',\n",
       " 'parent_id': 't3_22569',\n",
       " 'retrieved_on': 1473821517,\n",
       " 'score': 0,\n",
       " 'stickied': False,\n",
       " 'subreddit': 'reddit.com',\n",
       " 'subreddit_id': 't5_6',\n",
       " 'ups': 0}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.find()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80747895"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe = [\n",
    "    {\"$group\": \n",
    "     {\"_id\": \"$author\", \n",
    "      \"text\": {\"$push\": \"$body\"},\n",
    "      \"count\": {\"$sum\": 1},\n",
    "#     \"score\": {\"$sum\": \"$score\"},\n",
    "     \"controversiality\": {\"$sum\": \"$controversiality\"},\n",
    "      \"ups\": {\"$sum\": \"$ups\"},\n",
    "     \"downs\": {\"$sum\": \"$downs\"}}},\n",
    "#     \"subreddits\": {\"$push\": \"$subreddit\"}}},\n",
    "#     \"score\": {\"$push\": \"$score\"}}},\n",
    "#    {\"$group\":\n",
    "#     {\"_id\": \"$ups\",\n",
    "#     \"ups\": {\"$sum\": '$score'}}},\n",
    "#    {\"$group\":\n",
    "#     {\"_id\": \"$score\",\n",
    "#     \"score\": {\"$sum\": '$score'}}},\n",
    "#     {\"ups\":{\"$sum\":\"$ups\"}},\n",
    "#     {\"score\":{\"$sum\":\"$score\"}},\n",
    "    {'$limit': 100}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#cur = comments.aggregate(pipe,allowDiskUse = True).maxScan(100)\n",
    "with open('abc.csv', 'w') as outfile:\n",
    "    fields = ['postcode', 'upline', 'cit_state', 'contact_person', 'contact_no','nominal_level', 'credit', 'level', 'account_holder', 'merchantid', 'email', 'bank', 'reg_date' ,'address','acc_no','company_name']\n",
    "    writer = csv.DictWriter(outfile, fieldnames=fields)\n",
    "    writer.writeheader()\n",
    "    for x in cursor:\n",
    "        writer.writerow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for obj in comments.find():\n",
    "\n",
    "    if obj['body'] != '[deleted]':\n",
    "        d.append({'author':obj['author'],'text':obj['body'],'controversiality':obj['controversiality'],\n",
    "                  'score':obj['score'], 'subreddit':obj['subreddit_id']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29885845"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(d).to_csv('29mio.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('fletcher_500k.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove deleted users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df[df['author'] != '[deleted]'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df_sorted = df.sort_values('author')\n",
    "df = df.sort_values('author')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group by author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_group = df.groupby('author').apply(lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>controversiality</th>\n",
       "      <th>score</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12966</th>\n",
       "      <td>--k</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Help!!! He's influencing me!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323974</th>\n",
       "      <td>-Buzza-</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>The makers must have seen \"Snakes on a Plane\" ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286306</th>\n",
       "      <td>-Buzza-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I have seen a longer version of this video and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321994</th>\n",
       "      <td>-Buzza-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>\"I'd also think that a C&amp;amp;W audience would ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399529</th>\n",
       "      <td>-Yh-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>You should learn to read. If you sign up for a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         author  controversiality  score  \\\n",
       "12966       --k               0.0    0.0   \n",
       "323974  -Buzza-               1.0    2.0   \n",
       "286306  -Buzza-               0.0    1.0   \n",
       "321994  -Buzza-               0.0    3.0   \n",
       "399529     -Yh-               0.0    1.0   \n",
       "\n",
       "                                                     text  \n",
       "12966                      Help!!! He's influencing me!!!  \n",
       "323974  The makers must have seen \"Snakes on a Plane\" ...  \n",
       "286306  I have seen a longer version of this video and...  \n",
       "321994  \"I'd also think that a C&amp;W audience would ...  \n",
       "399529  You should learn to read. If you sign up for a...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>controversiality</th>\n",
       "      <th>score</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>000</th>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0sn</th>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1800doctorb</th>\n",
       "      <td>79</td>\n",
       "      <td>79</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9jack9</th>\n",
       "      <td>237</td>\n",
       "      <td>237</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9ner</th>\n",
       "      <td>462</td>\n",
       "      <td>462</td>\n",
       "      <td>462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             controversiality  score  text\n",
       "author                                    \n",
       "000                        61     61    61\n",
       "0sn                        72     72    72\n",
       "1800doctorb                79     79    79\n",
       "9jack9                    237    237   237\n",
       "9ner                      462    462   462"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('author').agg('count')[df.groupby('author').agg('count').text > 50].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('This', 'DT'), ('is', 'VBZ'), ('exactly', 'RB'), ('the', 'DT'), ('same', 'JJ'), ('behavior', 'NN'), ('as', 'IN'), ('the', 'DT'), ('very', 'RB'), ('early', 'JJ'), ('lisp', 'NN'), ('dialects', 'NNS'), (':', ':'), ('they', 'PRP'), ('had', 'VBD'), ('dynamic', 'JJ'), ('scoping', 'NN'), ('in', 'IN'), ('the', 'DT'), ('interpreter', 'NN'), ('and', 'CC'), ('lexical', 'JJ'), ('scoping', 'NN'), ('in', 'IN'), ('the', 'DT'), ('interpreter', 'NN'), ('.', '.'), ('I', 'PRP'), ('wonder', 'VBP'), ('if', 'IN'), ('they', 'PRP'), ('knew', 'VBD'), ('about', 'IN'), ('the', 'DT'), ('history', 'NN'), (',', ','), ('or', 'CC'), ('not', 'RB'), ('?', '.')]\n"
     ]
    }
   ],
   "source": [
    "tokens = word_tokenize(words)\n",
    "print(pos_tag(tokens))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
